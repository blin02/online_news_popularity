shiny::runApp('Documents/DataScience/projects/web_scraping')
shiny::runApp('Documents/DataScience/projects/web_scraping')
shiny::runApp('Documents/DataScience/projects/web_scraping')
shiny::runApp('Documents/DataScience/projects/web_scraping')
shiny::runApp('Documents/DataScience/projects/web_scraping')
library(flexclust) #Loading the flexclust library.
install.packages(flexclust)
install.packages('flexclust')
data(nutrient) #Loading the nutrient data.
library(flexclust) #Loading the flexclust library.
data(nutrient) #Loading the nutrient data.
help(nutrient) #Inspecting the data set; nutrients in meat, fish, and fowel.
nutrient
nutrient.scaled = as.data.frame(scale(nutrient))
summary(nutrient.scaled)
sapply(nutrient.scaled, sd)
d = dist(nutrient.scaled)
d
fit.single = hclust(d, method = "single")
fit.complete = hclust(d, method = "complete")
fit.average = hclust(d, method = "average")
par(mfrow = c(1, 3))
plot(fit.single, hang = -1, main = "Dendrogram of Single Linkage")
plot(fit.complete, hang = -1, main = "Dendrogram of Complete Linkage")
plot(fit.average, hang = -1, main = "Dendrogram of Average Linkage")
clusters.average = cutree(fit.average, k = 5)
clusters.average
clusters.average = cutree(fit.average, k = 2)
clusters.average
table(clusters.average)
clusters.average = cutree(fit.average, k = 3)
clusters.average
#Viewing the groups of data.
table(clusters.average)
clusters.average = cutree(fit.average, k = 4)
clusters.average
#Viewing the groups of data.
table(clusters.average)
clusters.average = cutree(fit.average, k = 6)
clusters.average
#Viewing the groups of data.
table(clusters.average)
clusters.average = cutree(fit.average, k = 5)
clusters.average
#Viewing the groups of data.
table(clusters.average)
aggregate(nutrient, by = list(cluster = clusters.average), median)
#Aggregating the scaled data by the cluster assignments.
aggregate(nutrient.scaled, by = list(cluster = clusters.average), median)
rect.hclust(fit.average, k = 5)
par(mfrow = c(1, 1))
plot(fit.average, hang = -1, main = "Dendrogram of Average Linkage\n5 Clusters")
rect.hclust(fit.average, k = 5)
clusters.average = cutree(fit.average, k = 5)
clusters.average
#Viewing the groups of data.
table(clusters.average)
#Aggregating the original data by the cluster assignments.
aggregate(nutrient, by = list(cluster = clusters.average), median)
#Aggregating the scaled data by the cluster assignments.
aggregate(nutrient.scaled, by = list(cluster = clusters.average), median)
#Visualizing the groups in the dendrogram.
par(mfrow = c(1, 1))
plot(fit.average, hang = -1, main = "Dendrogram of Average Linkage\n5 Clusters")
rect.hclust(fit.average, k = 5)
fit.single = hclust(d, method = "single")
fit.complete = hclust(d, method = "complete")
fit.average = hclust(d, method = "average")
#Creating various dendrograms.
par(mfrow = c(1, 3))
plot(fit.single, hang = -1, main = "Dendrogram of Single Linkage")
plot(fit.complete, hang = -1, main = "Dendrogram of Complete Linkage")
plot(fit.average, hang = -1, main = "Dendrogram of Average Linkage")
#Cut the dendrogram into groups of data.
clusters.average = cutree(fit.average, k = 5)
clusters.average
#Viewing the groups of data.
table(clusters.average)
#Aggregating the original data by the cluster assignments.
aggregate(nutrient, by = list(cluster = clusters.average), median)
#Aggregating the scaled data by the cluster assignments.
aggregate(nutrient.scaled, by = list(cluster = clusters.average), median)
#Visualizing the groups in the dendrogram.
par(mfrow = c(1, 1))
plot(fit.average, hang = -1, main = "Dendrogram of Average Linkage\n5 Clusters")
rect.hclust(fit.average, k = 5)
library(flexclust) #Loading the flexclust library.
data(nutrient) #Loading the nutrient data.
help(nutrient) #Inspecting the data set; nutrients in meat, fish, and fowel.
nutrient
#Notice that the nutrient columns are in different measurements: calories,
#grams, and milligrams.
summary(nutrient)
sapply(nutrient, sd)
#We should scale the data.
nutrient.scaled = as.data.frame(scale(nutrient))
summary(nutrient.scaled)
sapply(nutrient.scaled, sd)
#We need to calcualte the pairwise distances between observations.
d = dist(nutrient.scaled)
#Using the hclust() function, we define the linkage manner by which we will
#cluster our data.
fit.single = hclust(d, method = "single")
fit.complete = hclust(d, method = "complete")
fit.average = hclust(d, method = "average")
#Creating various dendrograms.
par(mfrow = c(1, 3))
plot(fit.single, hang = -1, main = "Dendrogram of Single Linkage")
plot(fit.complete, hang = -1, main = "Dendrogram of Complete Linkage")
plot(fit.average, hang = -1, main = "Dendrogram of Average Linkage")
#Cut the dendrogram into groups of data.
clusters.average = cutree(fit.average, k = 5)
clusters.average
#Viewing the groups of data.
table(clusters.average)
#Aggregating the original data by the cluster assignments.
aggregate(nutrient, by = list(cluster = clusters.average), median)
#Aggregating the scaled data by the cluster assignments.
aggregate(nutrient.scaled, by = list(cluster = clusters.average), median)
#Visualizing the groups in the dendrogram.
par(mfrow = c(1, 1))
plot(fit.average, hang = -1, main = "Dendrogram of Average Linkage\n5 Clusters")
rect.hclust(fit.average, k = 5)
shiny::runApp('Documents/DataScience/projects/web_scraping/web_sraping_app')
shiny::runApp('Documents/DataScience/projects/web_scraping/web_sraping_app')
shiny::runApp('Documents/DataScience/projects/web_scraping/web_sraping_app')
shiny::runApp('Documents/DataScience/projects/web_scraping/web_sraping_app')
shiny::runApp('Documents/DataScience/projects/web_scraping/web_sraping_app')
shiny::runApp('Documents/DataScience/projects/web_scraping/web_sraping_app')
shiny::runApp('Documents/DataScience/projects/web_scraping/web_sraping_app')
articles$author
View(by_topic)
View(by_topic)
View(articles.scaled)
shiny::runApp('Documents/DataScience/projects/web_scraping/web_sraping_app')
by_author = group_by(articles.reduced, author)
arrange(summarise(by_author, count = n()), desc(count))
by_author = group_by(articles.reduced, author)
by_author
head(by_author)
head(by_author, 10)
top.authors = arrange(summarise(by_author, count = n()), desc(count))
head(top.author, 10)
top.authors = arrange(summarise(by_author, count = n()), desc(count))
head(top.authors, 10)
shiny::runApp('Documents/DataScience/projects/web_scraping/web_sraping_app')
by_author = group_by(articles.reduced, author)
top.authors = arrange(summarise(by_author, count = n()), desc(count))
top.authors = head(top.authors, 10)
articles.top.authors = articles.reduced[author %in% top.authors$author,]
articles.top.authors = articles.reduced[articles.reduced$author %in% top.authors$author,]
articles.top.authors
top.authors
articles.top.authors = articles.reduced[articles.reduced$author %in% top.authors$author, ]
articles.top.authors
aritlces
articles
articles.reduced
top.authors$autho
top.authors$author
top.authors = head(top.authors, 5)
top.authors$author
articles.top.authors = articles.reduced[articles.reduced$author %in% top.authors$author, ]
articles.top.authors
articles.top.authors = filter(articles.reduced, author %in% top.authors$author]
articles.top.authors = filter(articles.reduced, author %in% top.authors$author)
articles.top.authors
shiny::runApp('Documents/DataScience/projects/web_scraping/web_sraping_app')
shiny::runApp('Documents/DataScience/projects/web_scraping/web_sraping_app')
hist(Sales)
library(tree)
#Loading the ISLR library in order to use the Carseats dataset.
library(ISLR)
#Making data manipulation easier.
help(Carseats)
attach(Carseats)
#Looking at the variable of interest, Sales.
hist(Sales)
summary(Sales)
High = ifelse(Sales <= 8, "No", "Yes")
Carseats = data.frame(Carseats, High)
summary(tree.carseats)
plot(tree.carseats)
tree.carseats = tree(High ~ . - Sales, split = "gini", data = Carseats)
summary(tree.carseats)
High = ifelse(Sales <= 8, "No", "Yes")
Carseats = data.frame(Carseats, High)
#Fit a tree to the data; note that we are excluding Sales from the formula.
tree.carseats = tree(High ~ . - Sales, split = "gini", data = Carseats)
library(tree)
library(ISLR)
tree.carseats = tree(High ~ . - Sales, split = "gini", data = Carseats)
install.packages('tree')
install.packages('ISLR')
library(tree)
library(ISLR)
tree.carseats = tree(High ~ . - Sales, split = "gini", data = Carseats)
summary(tree.carseats)
plot(tree.carseats)
text(tree.carseats, pretty = 0) #Yields category names instead of dummy variables.
tree.carseats
hist(Sales)
summary(Sales)
High = ifelse(Sales <= 8, "No", "Yes")
Carseats = data.frame(Carseats, High)
tree.carseats = tree(High ~ . - Sales, split = "gini", data = Carseats)
summary(tree.carseats)
plot(tree.carseats)
text(tree.carseats, pretty = 0) #Yields category names instead of dummy variables.
tree.carseats
tree.carseats
library(tree)
#Loading the ISLR library in order to use the Carseats dataset.
#install.packages('ISLR')
library(ISLR)
#Making data manipulation easier.
help(Carseats)
attach(Carseats)
#Looking at the variable of interest, Sales.
hist(Sales)
detach("package:googleCharts", unload=TRUE)
detach("package:googleVis", unload=TRUE)
library(tree)
#Loading the ISLR library in order to use the Carseats dataset.
#install.packages('ISLR')
library(ISLR)
#Making data manipulation easier.
help(Carseats)
attach(Carseats)
#Looking at the variable of interest, Sales.
hist(Sales)
summary(Sales)
High = ifelse(Sales <= 8, "No", "Yes")
Carseats = data.frame(Carseats, High)
#Fit a tree to the data; note that we are excluding Sales from the formula.
tree.carseats = tree(High ~ . - Sales, split = "gini", data = Carseats)
summary(tree.carseats)
# rResidual mean deviance is actually "Gini", prefer smaller Gini
#The output shows the variables actually used within the tree, the number of
#terminal nodes, the residual mean deviance based on the Gini index, and
#the misclassification error rate.
#Plotting the classification tree.
plot(tree.carseats)
text(tree.carseats, pretty = 0) #Yields category names instead of dummy variables.
#Detailed information for the splits of the classification tree.
tree.carseats
plot(tree.carseats)
library(tree)
#Loading the ISLR library in order to use the Carseats dataset.
#install.packages('ISLR')
library(ISLR)
#Making data manipulation easier.
help(Carseats)
attach(Carseats)
hist(Sales)
summary(Sales)
High = ifelse(Sales <= 8, "No", "Yes")
Carseats = data.frame(Carseats, High)
#Fit a tree to the data; note that we are excluding Sales from the formula.
tree.carseats = tree(High ~ . - Sales, split = "gini", data = Carseats)
summary(tree.carseats)
# rResidual mean deviance is actually "Gini", prefer smaller Gini
#The output shows the variables actually used within the tree, the number of
#terminal nodes, the residual mean deviance based on the Gini index, and
#the misclassification error rate.
#Plotting the classification tree.
plot(tree.carseats)
library(tree)
library(ISLR)
help(Carseats)
attach(Carseats)
#Looking at the variable of interest, Sales.
hist(Sales)
summary(Sales)
#Creating a binary categorical variable High based on the continuous Sales
#variable and adding it to the original data frame.
High = ifelse(Sales <= 8, "No", "Yes")
Carseats = data.frame(Carseats, High)
#Fit a tree to the data; note that we are excluding Sales from the formula.
tree.carseats = tree(High ~ . - Sales, split = "gini", data = Carseats)
summary(tree.carseats)
# rResidual mean deviance is actually "Gini", prefer smaller Gini
#The output shows the variables actually used within the tree, the number of
#terminal nodes, the residual mean deviance based on the Gini index, and
#the misclassification error rate.
#Plotting the classification tree.
plot(tree.carseats)
text(tree.carseats, pretty = 0) #Yields category names instead of dummy variables.
#Detailed information for the splits of the classification tree.
tree.carseats
tree.carseats = tree(High ~ . - Sales, data = Carseats, subset = train)
plot(tree.carseats)
text(tree.carseats, pretty = 0)
summary(tree.carseats)
tree.carseats
#Using the trained decision tree to classify the test data.
tree.pred = predict(tree.carseats, Carseats.test, type = "class")
tree.pred
library(MASS)
help(Boston)
?predict
library(MASS)
help(Boston)
set.seed(0)
train = sample(1:nrow(Boston), 7*nrow(Boston)/10)
tree.boston = tree(medv ~ ., Boston, subset = train)
summary(tree.boston)
tree.boston = tree(medv ~ ., Boston, subset = train)
summary(tree.boston)
#Visually inspecting the regression tree.
plot(tree.boston)
text(tree.boston, pretty = 0)
#Performing cross-validation.
set.seed(0)
cv.boston = cv.tree(tree.boston)
par(mfrow = c(1, 2))
plot(cv.boston$size, cv.boston$dev, type = "b",
xlab = "Terminal Nodes", ylab = "RSS")
plot(cv.boston$k, cv.boston$dev, type  = "b",
xlab = "Alpha", ylab = "RSS")
#Pruning the tree to have 4 terminal nodes.
prune.boston = prune.tree(tree.boston, best = 4)
par(mfrow = c(1, 1))
plot(prune.boston)
text(prune.boston, pretty = 0)
#Calculating and assessing the MSE of the test data on the overall tree.
yhat = predict(tree.boston, newdata = Boston[-train, ])
yhat
boston.test = Boston[-train, "medv"]
boston.test
plot(yhat, boston.test)
abline(0, 1)
mean((yhat - boston.test)^2)
set.seed(0)
train = sample(1:nrow(Boston), 7*nrow(Boston)/10)
#Training the tree to predict the median value of owner-occupied homes (in $1k).
tree.boston = tree(medv ~ ., Boston, subset = train)
summary(tree.boston)
#Visually inspecting the regression tree.
plot(tree.boston)
text(tree.boston, pretty = 0)
#Performing cross-validation.
set.seed(0)
cv.boston = cv.tree(tree.boston)
par(mfrow = c(1, 2))
plot(cv.boston$size, cv.boston$dev, type = "b",
xlab = "Terminal Nodes", ylab = "RSS")
plot(cv.boston$k, cv.boston$dev, type  = "b",
xlab = "Alpha", ylab = "RSS")
?medv
medv
medv
train$medv
train
head(train)
?tree
prune.boston = prune.tree(tree.boston, best = 4)
par(mfrow = c(1, 1))
plot(prune.boston)
text(prune.boston, pretty = 0)
#Calculating and assessing the MSE of the test data on the overall tree.
prune.boston = prune.tree(tree.boston, best = 4)
par(mfrow = c(1, 1))
plot(prune.boston)
text(prune.boston, pretty = 0)
yhat = predict(tree.boston, newdata = Boston[-train, ])
yhat
boston.test = Boston[-train, "medv"]
boston.test
head(bonston)
head(boston)
head(Boston)
train
yhat = predict(prune.boston, newdata = Boston[-train, ])
yhat
plot(yhat, boston.test)
abline(0, 1)
mean((yhat - boston.test)^2)
library(randomForest)
install.packages('randomForest')
library(randomForest)
set.seed(0)
rf.boston = randomForest(medv ~ ., data = Boston, subset = train, importance = TRUE)
rf.boston
?randomForest
set.seed(0)
oob.err = numeric(13)
for (mtry in 1:13) {
fit = randomForest(medv ~ ., data = Boston[train, ], mtry = mtry)
oob.err[mtry] = fit$mse[500]
cat("We're performing iteration", mtry, "\n")
}
#Visualizing the OOB error.
plot(1:13, oob.err, pch = 16, type = "b",
xlab = "Variables Considered at Each Split",
ylab = "OOB Mean Squared Error",
main = "Random Forest OOB Error Rates\nby # of Variables")
importance(rf.boston)
varImpPlot(rf.boston)
library(gbm)
install.packages('gbm')
set.seed(0)
boost.boston = gbm(medv ~ ., data = Boston[train, ],
distribution = "gaussian",
n.trees = 10000,
interaction.depth = 4)
library(gbm)    #not just for trees
set.seed(0)
boost.boston = gbm(medv ~ ., data = Boston[train, ],
distribution = "gaussian",
n.trees = 10000,
interaction.depth = 4)
par(mfrow = c(1, 1))
summary(boost.boston)
par(mfrow = c(1, 2))
plot(boost.boston, i = "rm")
plot(boost.boston, i = "lstat")
shiny::runApp('Documents/DataScience/projects/web_scraping/web_sraping_app')
shiny::runApp('Documents/DataScience/projects/web_scraping/web_sraping_app')
write.csv(articles, 'data/articles.csv', row.names=FALSE)
setwd('/Users/binlin/Documents/DataScience/projects/web_scraping/web_sraping_app/')
json_file = "data/marshable_article_detail_2016-02-24-214055396.json"
articles = fromJSON(json_file, simplifyDataFrame = TRUE, )
library("jsonlite")
library(dplyr)
setwd('/Users/binlin/Documents/DataScience/projects/web_scraping/web_sraping_app/')
json_file = "data/marshable_article_detail_2016-02-24-214055396.json"
articles = fromJSON(json_file, simplifyDataFrame = TRUE, )
row.names(articles)<-NULL
articles = select(articles, id = X_id)
articles.reduced = select(articles, -content, -title, -topics, -link)
summary(articles.reduced)
write.csv(articles, 'data/articles.csv', row.names=FALSE)
write.csv(articles.reduced, 'data/articles_reduced.csv', row.names=FALSE)
shiny::runApp()
shiny::runApp()
setwd('/Users/binlin/Documents/DataScience/projects/web_scraping/web_sraping_app/data/')
articles = read.csv("./articles.csv", na.strings = "NA", stringsAsFactors = FALSE)
articles = read.csv("./articles.csv", na.strings = "NA", stringsAsFactors = FALSE)
shiny::runApp('~/Documents/DataScience/projects/web_scraping/web_sraping_app')
head(articles.reduced)
library("jsonlite")
library(dplyr)
setwd('/Users/binlin/Documents/DataScience/projects/web_scraping/web_sraping_app/')
json_file = "data/marshable_article_detail_2016-02-24-214055396.json"
articles = fromJSON(json_file, simplifyDataFrame = TRUE, )
row.names(articles)<-NULL
articles = select(articles, id = X_id)
articles.reduced = select(articles, -content, -title, -topics, -link)
summary(articles.reduced)
write.csv(articles, 'data/articles.csv', row.names=FALSE)
write.csv(articles.reduced, 'data/articles_reduced.csv', row.names=FALSE)
setwd('/Users/binlin/Documents/DataScience/projects/web_scraping/web_sraping_app/')
json_file = "data/marshable_article_list_2016-02-24-095828259.json"
articles = fromJSON(json_file, simplifyDataFrame = TRUE, )
row.names(articles)<-NULL
articles = select(articles, id = X_id)
articles.reduced = select(articles, -content, -title, -topics, -link)
summary(articles.reduced)
write.csv(articles, 'data/articles.csv', row.names=FALSE)
write.csv(articles.reduced, 'data/articles_reduced.csv', row.names=FALSE)
shiny::runApp()
library("jsonlite")
library(dplyr)
setwd('/Users/binlin/Documents/DataScience/projects/web_scraping/web_sraping_app/')
json_file = "data/marshable_article_detail_2016-02-24-221140219.json"
articles = fromJSON(json_file, simplifyDataFrame = TRUE, )
row.names(articles)<-NULL
articles = select(articles, id = X_id)
articles.reduced = select(articles, -content, -title, -topics, -link)
summary(articles.reduced)
write.csv(articles, 'data/articles.csv', row.names=FALSE)
write.csv(articles.reduced, 'data/articles_reduced.csv', row.names=FALSE)
shiny::runApp()
library("jsonlite")
library(dplyr)
setwd('/Users/binlin/Documents/DataScience/projects/web_scraping/web_sraping_app/')
json_file = "data/marshable_article_detail_2016-02-25-002010986.json"
articles = fromJSON(json_file, simplifyDataFrame = TRUE, )
row.names(articles)<-NULL
articles = select(articles, id = X_id)
articles.reduced = select(articles, -content, -title, -topics, -link)
summary(articles.reduced)
write.csv(articles, 'data/articles.csv', row.names=FALSE)
write.csv(articles.reduced, 'data/articles_reduced.csv', row.names=FALSE)
shiny::runApp()
setwd('/Users/binlin/Documents/DataScience/projects/web_scraping/web_sraping_app/')
json_file = "data/marshable_article_detail_2016-02-25-002010986.json"
articles = fromJSON(json_file, simplifyDataFrame = TRUE )
row.names(articles)<-NULL
articles_with_just_id = select(articles, id)
articles_without_id = select(articles, -id)
articles_merged = merge(articles_with_just_id, articles_without_id)
articles.reduced = select(articles, -content, -title, -topics, -link)
summary(articles.reduced)
write.csv(articles_merged, 'data/articles.csv', row.names=FALSE)
setwd('/Users/binlin/Documents/DataScience/projects/web_scraping/web_sraping_app/')
json_file = "data/marshable_article_detail_2016-02-25-002010986.json"
articles = fromJSON(json_file, simplifyDataFrame = TRUE )
row.names(articles)<-NULL
articles_with_just_id = select(articles, id)
articles_without_id = select(articles, -id)
articles_merged = merge(articles_with_just_id, articles_without_id)
articles.reduced = select(articles, -content, -title, -topics, -link)
summary(articles.reduced)
write.csv(articles_merged, 'data/articles.csv', row.names=FALSE)
write.csv(articles.reduced, 'data/articles_reduced.csv', row.names=FALSE)
summary(articles_merged)
head(articles_with_just_id)
head(articles_without_id)
shiny::runApp()
shiny::runApp()
